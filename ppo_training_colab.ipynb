{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9284647",
   "metadata": {},
   "source": [
    "![MuJoCo banner](https://raw.githubusercontent.com/google-deepmind/mujoco/main/banner.png)\n",
    "\n",
    "# <h1><center>PPO Training for Piper Robot <a href=\"https://colab.research.google.com/github/wzzzzq/MuJoCo_Visual_PPO/blob/main/ppo_training_colab.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"140\" align=\"center\"/></a></center></h1>\n",
    "\n",
    "This notebook provides a complete training pipeline for PPO (Proximal Policy Optimization) on a Piper robot arm grasping task using MuJoCo physics simulation. The training uses visual observations (RGB cameras) combined with state information.\n",
    "\n",
    "## ‚öôÔ∏è Requirements\n",
    "\n",
    "**Important:** Make sure you're using a **GPU runtime** in Google Colab:\n",
    "1. Go to `Runtime` ‚Üí `Change runtime type`\n",
    "2. Select `GPU` as the hardware accelerator\n",
    "3. Choose `T4`, `V100`, or `A100` if available\n",
    "\n",
    "## üéØ What This Notebook Does\n",
    "\n",
    "1. **Environment Setup**: Installs MuJoCo with proper GPU rendering support\n",
    "2. **Repository Setup**: Clones the training code and verifies all assets\n",
    "3. **Training**: Runs PPO training with visual observations\n",
    "4. **Evaluation**: Tests the trained policy and visualizes results\n",
    "5. **Model Management**: Saves trained models to Google Drive\n",
    "\n",
    "## üìä Expected Results\n",
    "\n",
    "- Training time: ~30-60 minutes (depending on GPU)\n",
    "- The robot learns to grasp and manipulate objects using camera inputs\n",
    "- Final models are automatically saved to your Google Drive\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ef3ba",
   "metadata": {},
   "source": [
    "# PPO Training for Piper Robot in Google Colab\n",
    "\n",
    "This notebook sets up the environment and trains a PPO agent for the Piper robot arm grasping task using MuJoCo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdfd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPU rendering (following official MuJoCo tutorial pattern)\n",
    "from google.colab import files\n",
    "import distutils.util\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Check GPU availability\n",
    "if subprocess.run('nvidia-smi').returncode:\n",
    "  raise RuntimeError(\n",
    "      'Cannot communicate with GPU. '\n",
    "      'Make sure you are using a GPU Colab runtime. '\n",
    "      'Go to the Runtime menu and select Choose runtime type.')\n",
    "\n",
    "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
    "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
    "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
    "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
    "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
    "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
    "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
    "    f.write(\"\"\"{\n",
    "    \"file_format_version\" : \"1.0.0\",\n",
    "    \"ICD\" : {\n",
    "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl\n",
    "\n",
    "# Install system dependencies\n",
    "!apt-get update\n",
    "!apt-get install -y \\\n",
    "    libgl1-mesa-dev \\\n",
    "    libgl1-mesa-glx \\\n",
    "    libglew-dev \\\n",
    "    libosmesa6-dev \\\n",
    "    libegl1-mesa-dev \\\n",
    "    software-properties-common \\\n",
    "    patchelf \\\n",
    "    libglfw3-dev\n",
    "\n",
    "# Install MuJoCo\n",
    "!pip install mujoco\n",
    "\n",
    "# Check if installation was successful\n",
    "try:\n",
    "  print('Checking that the installation succeeded:')\n",
    "  import mujoco\n",
    "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
    "except Exception as e:\n",
    "  raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "\n",
    "print('MuJoCo installation successful.')\n",
    "\n",
    "# Install other Python dependencies\n",
    "!pip install torch>=2.0.0\n",
    "!pip install numpy==1.26.4\n",
    "!pip install scipy>=1.7.0\n",
    "!pip install gymnasium==0.28.1\n",
    "!pip install imageio\n",
    "!pip install imageio[ffmpeg]\n",
    "!pip install imageio[pyav]\n",
    "!pip install tyro>=0.5.0\n",
    "!pip install tqdm>=4.60.0\n",
    "\n",
    "print('All dependencies installed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc722390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "# Replace with your actual GitHub repository URL\n",
    "repo_url = \"https://github.com/wzzzzq/MuJoCo_Visual_PPO.git\"\n",
    "repo_name = \"MuJoCo_Visual_PPO\"\n",
    "\n",
    "# Check if repository already exists\n",
    "if os.path.exists(f\"/content/{repo_name}\"):\n",
    "    print(f\"Repository {repo_name} already exists. Pulling latest changes...\")\n",
    "    %cd /content/{repo_name}\n",
    "    !git pull\n",
    "else:\n",
    "    print(f\"Cloning repository from {repo_url}...\")\n",
    "    %cd /content\n",
    "    !git clone {repo_url}\n",
    "    %cd {repo_name}\n",
    "\n",
    "# Verify the clone was successful\n",
    "print(\"Repository contents:\")\n",
    "!ls -la\n",
    "\n",
    "# Verify key files exist\n",
    "required_files = ['single_piper_on_desk_env.py', 'ppo_rgb.py', 'model_assets/piper_on_desk/scene.xml']\n",
    "missing_files = []\n",
    "for file in required_files:\n",
    "    if not os.path.exists(file):\n",
    "        missing_files.append(file)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"Warning: Missing required files: {missing_files}\")\n",
    "    print(\"Please check that the repository contains all necessary files.\")\n",
    "else:\n",
    "    print(\"All required files found successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d967987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to save models and logs\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for saving models\n",
    "!mkdir -p /content/drive/MyDrive/ppo_training_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cba65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports and helper functions for the notebook\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# Set up matplotlib for better plots in Colab\n",
    "plt.style.use('default')\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
    "\n",
    "def print_section(title, char=\"=\", width=50):\n",
    "    \"\"\"Print a formatted section header\"\"\"\n",
    "    print(char * width)\n",
    "    print(f\" {title} \".center(width))\n",
    "    print(char * width)\n",
    "\n",
    "def print_success(message):\n",
    "    \"\"\"Print a success message with emoji\"\"\"\n",
    "    print(f\"‚úì {message}\")\n",
    "\n",
    "def print_error(message):\n",
    "    \"\"\"Print an error message with emoji\"\"\"\n",
    "    print(f\"‚ùå {message}\")\n",
    "\n",
    "def print_warning(message):\n",
    "    \"\"\"Print a warning message with emoji\"\"\"\n",
    "    print(f\"‚ö†Ô∏è  {message}\")\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Format seconds into a readable time string\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}s\"\n",
    "    elif seconds < 3600:\n",
    "        return f\"{seconds/60:.1f}m\"\n",
    "    else:\n",
    "        return f\"{seconds/3600:.1f}h\"\n",
    "\n",
    "print_success(\"Helper functions loaded successfully!\")\n",
    "print(\"Ready to proceed with MuJoCo setup...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e04199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic rendering test - following MuJoCo tutorial simple pattern\n",
    "print(\"üñºÔ∏è  Basic MuJoCo Rendering Test\")\n",
    "\n",
    "try:\n",
    "    # Load the Piper robot model directly (similar to tutorial approach)\n",
    "    import mujoco\n",
    "    import os\n",
    "    \n",
    "    # Find the model file\n",
    "    model_path = None\n",
    "    possible_paths = [\n",
    "        'model_assets/piper_on_desk/scene.xml',\n",
    "        '/content/MuJoCo_Visual_PPO/model_assets/piper_on_desk/scene.xml'\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            model_path = path\n",
    "            break\n",
    "    \n",
    "    if model_path:\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "        \n",
    "        # Load model and create data (tutorial pattern)\n",
    "        model = mujoco.MjModel.from_xml_path(model_path)\n",
    "        data = mujoco.MjData(model)\n",
    "        \n",
    "        # Basic rendering following exact tutorial pattern\n",
    "        with mujoco.Renderer(model, height=480, width=640) as renderer:\n",
    "            # Forward simulation to update positions (tutorial step)\n",
    "            mujoco.mj_forward(model, data)\n",
    "            renderer.update_scene(data)\n",
    "            \n",
    "            # Render and show the image (tutorial style)\n",
    "            pixels = renderer.render()\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(pixels)\n",
    "            plt.title('Piper Robot Environment - Basic MuJoCo Rendering\\n(Following Official Tutorial Pattern)', \n",
    "                     fontsize=14, fontweight='bold', pad=20)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Add technical info as text overlay (tutorial style)\n",
    "            plt.text(0.02, 0.98, f'Resolution: {pixels.shape[1]}√ó{pixels.shape[0]}\\nBackend: {os.environ.get(\"MUJOCO_GL\", \"default\")}', \n",
    "                    transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        print_success(\"Basic MuJoCo rendering test passed!\")\n",
    "        print(f\"‚úì Rendered {pixels.shape} image using tutorial pattern\")\n",
    "        print(\"‚úì Model loaded and rendered successfully\")\n",
    "        \n",
    "    else:\n",
    "        print_warning(\"Model file not found. This test requires the repository to be cloned first.\")\n",
    "        print(\"Please run the repository cloning cell first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print_error(f\"Basic rendering test failed: {e}\")\n",
    "    print(\"This is expected if MuJoCo or the model files are not yet available.\")\n",
    "    print(\"Please run the installation and repository setup cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "# Ensure MuJoCo is configured for EGL rendering (headless GPU rendering for Colab)\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "\n",
    "# Add the project directory to Python path\n",
    "project_path = f'/content/{repo_name}'  # Use the repo name from previous cell\n",
    "if os.path.exists(project_path):\n",
    "    sys.path.insert(0, project_path)  # Insert at beginning to ensure our modules are found first\n",
    "    os.chdir(project_path)\n",
    "    print(f\"Working directory set to: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Project path {project_path} not found. Please check the repository cloning step.\")\n",
    "    \n",
    "# Verify MuJoCo setup\n",
    "print(\"Verifying MuJoCo configuration...\")\n",
    "import mujoco\n",
    "print(f\"MuJoCo version: {mujoco.__version__}\")\n",
    "print(f\"MuJoCo GL backend: {os.environ.get('MUJOCO_GL', 'Not set')}\")\n",
    "\n",
    "# Test basic MuJoCo functionality\n",
    "try:\n",
    "    test_model = mujoco.MjModel.from_xml_string('<mujoco><worldbody><geom size=\"1\"/></worldbody></mujoco>')\n",
    "    test_data = mujoco.MjData(test_model)\n",
    "    mujoco.mj_step(test_model, test_data)\n",
    "    print(\"‚úì MuJoCo basic functionality test passed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó MuJoCo basic functionality test failed: {e}\")\n",
    "\n",
    "# Test MuJoCo rendering\n",
    "try:\n",
    "    with mujoco.Renderer(test_model, height=64, width=64) as renderer:\n",
    "        mujoco.mj_forward(test_model, test_data)\n",
    "        renderer.update_scene(test_data)\n",
    "        pixels = renderer.render()\n",
    "        print(f\"‚úì MuJoCo rendering test passed - rendered {pixels.shape} image\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó MuJoCo rendering test failed: {e}\")\n",
    "\n",
    "# Import project modules\n",
    "try:\n",
    "    from single_piper_on_desk_env import PiperEnv\n",
    "    from ppo_rgb import PPOArgs, train\n",
    "    import tyro\n",
    "    print(\"‚úì Project modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Failed to import project modules: {e}\")\n",
    "    print(\"Please check that all required files are in the repository.\")\n",
    "\n",
    "# Check PyTorch and CUDA setup\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Test the environment\n",
    "print(\"\\nTesting PiperEnv...\")\n",
    "try:\n",
    "    env = PiperEnv(render_mode=None)  # No GUI rendering in headless Colab\n",
    "    obs, info = env.reset()\n",
    "    print(f\"‚úì Environment created successfully\")\n",
    "    print(f\"  Observation space: {env.observation_space}\")\n",
    "    print(f\"  Action space: {env.action_space}\")\n",
    "    print(f\"  Observation keys: {list(obs.keys())}\")\n",
    "    print(f\"  RGB image shape: {obs['rgb'].shape}\")\n",
    "    print(f\"  Wrist camera shape: {obs['wrist_cam'].shape}\")\n",
    "    print(f\"  State shape: {obs['state'].shape}\")\n",
    "    \n",
    "    # Test a few steps\n",
    "    for i in range(3):\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        print(f\"  Step {i+1}: reward={reward:.3f}\")\n",
    "    \n",
    "    env.close()\n",
    "    print(\"‚úì Environment test completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Environment test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"Please check that all model assets are properly included in the repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6480728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate camera rendering - following MuJoCo tutorial pattern\n",
    "print_section(\"Camera Rendering Demonstration\")\n",
    "\n",
    "try:\n",
    "    # Create environment for rendering demo\n",
    "    env = PiperEnv(render_mode=None)\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    # Take a few random steps to create an interesting scene\n",
    "    for i in range(10):\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            obs, info = env.reset()\n",
    "    \n",
    "    print(\"üì∏ Capturing camera views using MuJoCo tutorial rendering pattern...\")\n",
    "    \n",
    "    # Get both camera views using the exact same method as the tutorial\n",
    "    rgb_view = obs['rgb']\n",
    "    wrist_view = obs['wrist_cam']\n",
    "    \n",
    "    # Display both cameras side by side (following tutorial style)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Third-person camera view\n",
    "    ax1.imshow(rgb_view)\n",
    "    ax1.set_title('Third-Person Camera View\\n(External perspective)', fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    ax1.text(0.5, -0.05, f'Resolution: {rgb_view.shape[1]}√ó{rgb_view.shape[0]}', \n",
    "             ha='center', va='top', transform=ax1.transAxes, fontsize=10)\n",
    "    \n",
    "    # Wrist camera view  \n",
    "    ax2.imshow(wrist_view)\n",
    "    ax2.set_title('Wrist Camera View\\n(Robot end-effector perspective)', fontsize=12, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    ax2.text(0.5, -0.05, f'Resolution: {wrist_view.shape[1]}√ó{wrist_view.shape[0]}', \n",
    "             ha='center', va='top', transform=ax2.transAxes, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('MuJoCo Piper Robot Camera Views', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    # Show some technical details about the rendering\n",
    "    print(f\"\\nüîç Technical Details:\")\n",
    "    print(f\"  Third-person camera shape: {rgb_view.shape}\")\n",
    "    print(f\"  Wrist camera shape: {wrist_view.shape}\")\n",
    "    print(f\"  Data type: {rgb_view.dtype}\")\n",
    "    print(f\"  Value range: [{rgb_view.min()}, {rgb_view.max()}]\")\n",
    "    print(f\"  Rendering backend: {os.environ.get('MUJOCO_GL', 'default')}\")\n",
    "    \n",
    "    # Demonstrate the rendering pipeline (following tutorial approach)\n",
    "    print(f\"\\n‚öôÔ∏è  Rendering Pipeline (following MuJoCo tutorial):\")\n",
    "    print(f\"  1. Environment step ‚Üí data.qpos, data.qvel updated\")\n",
    "    print(f\"  2. mj_forward() ‚Üí compute derived quantities\")  \n",
    "    print(f\"  3. Renderer context ‚Üí with mujoco.Renderer() as renderer:\")\n",
    "    print(f\"  4. renderer.update_scene() ‚Üí update visual scene\")\n",
    "    print(f\"  5. renderer.render() ‚Üí generate RGB pixels\")\n",
    "    \n",
    "    # Show a sequence of frames to demonstrate motion\n",
    "    print(f\"\\nüé¨ Demonstrating motion sequence...\")\n",
    "    \n",
    "    # Reset environment and take controlled steps\n",
    "    obs, info = env.reset()\n",
    "    frames_3rd = []\n",
    "    frames_wrist = []\n",
    "    \n",
    "    # Collect frames from a short sequence\n",
    "    for step in range(6):\n",
    "        # Use a more controlled action for better visualization\n",
    "        action = np.array([0.1, -0.1, 0.05, -0.05, 0.02, 0.1, 0.5])  # Deliberate movement\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        if step % 2 == 0:  # Collect every other frame\n",
    "            frames_3rd.append(obs['rgb'])\n",
    "            frames_wrist.append(obs['wrist_cam'])\n",
    "    \n",
    "    # Display motion sequence\n",
    "    num_frames = len(frames_3rd)\n",
    "    fig, axes = plt.subplots(2, num_frames, figsize=(3*num_frames, 6))\n",
    "    \n",
    "    if num_frames == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        # Third-person sequence\n",
    "        axes[0, i].imshow(frames_3rd[i])\n",
    "        axes[0, i].set_title(f'3rd Person\\nStep {i*2}', fontsize=10)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Wrist sequence  \n",
    "        axes[1, i].imshow(frames_wrist[i])\n",
    "        axes[1, i].set_title(f'Wrist Camera\\nStep {i*2}', fontsize=10)\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Motion Sequence - Both Camera Views', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    env.close()\n",
    "    print_success(\"Camera rendering demonstration completed!\")\n",
    "    print(\"‚úì Both camera views rendered successfully using MuJoCo tutorial pattern\")\n",
    "    print(\"‚úì Motion sequence captured and displayed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print_error(f\"Camera rendering demonstration failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e018f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure PPO training arguments\n",
    "ppo_args = PPOArgs()\n",
    "\n",
    "# Colab-optimized settings\n",
    "# Note: Adjust these based on your Colab runtime (T4, V100, etc.)\n",
    "ppo_args.total_timesteps = 500000   # Reduced for faster demo (increase to 1M+ for full training)\n",
    "ppo_args.num_envs = 3               # Fewer environments to reduce memory usage\n",
    "ppo_args.num_eval_envs = 1          # Single eval environment\n",
    "ppo_args.num_steps = 80             # Steps per environment per update\n",
    "ppo_args.num_minibatches = 4        # Number of minibatches for gradient updates\n",
    "ppo_args.learning_rate = 3e-4       # Standard learning rate\n",
    "ppo_args.track = False              # Disable wandb tracking for simplicity\n",
    "ppo_args.save_model = True          # Save model checkpoints\n",
    "ppo_args.cuda = torch.cuda.is_available()  # Use GPU if available\n",
    "\n",
    "# Reproducibility settings\n",
    "ppo_args.seed = 42\n",
    "ppo_args.torch_deterministic = True\n",
    "\n",
    "# Memory optimization for Colab\n",
    "ppo_args.batch_size = ppo_args.num_envs * ppo_args.num_steps  # Calculate batch size\n",
    "print(f\"Calculated batch size: {ppo_args.batch_size}\")\n",
    "\n",
    "print(\"PPO Configuration for Google Colab:\")\n",
    "print(f\"  Total timesteps: {ppo_args.total_timesteps:,}\")\n",
    "print(f\"  Number of environments: {ppo_args.num_envs}\")\n",
    "print(f\"  Steps per environment: {ppo_args.num_steps}\")\n",
    "print(f\"  Batch size: {ppo_args.batch_size}\")\n",
    "print(f\"  Learning rate: {ppo_args.learning_rate}\")\n",
    "print(f\"  Using CUDA: {ppo_args.cuda}\")\n",
    "print(f\"  Expected training time: ~{ppo_args.total_timesteps // (ppo_args.num_envs * ppo_args.num_steps * 60):.1f} minutes\")\n",
    "\n",
    "# Estimate memory usage\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    print(f\"\\nGPU Memory before training:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "# Start training with proper error handling\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting PPO training...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Create a simple environment test before training\n",
    "    test_env = PiperEnv(render_mode=None)\n",
    "    test_obs, _ = test_env.reset()\n",
    "    test_env.close()\n",
    "    print(\"‚úì Environment pre-check passed\")\n",
    "    \n",
    "    # Start actual training\n",
    "    train(args=ppo_args)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üéâ Training completed successfully!\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"‚ö†Ô∏è  Training interrupted by user\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"‚ùå Training failed with error: {e}\")\n",
    "    print(\"=\"*50)\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Provide helpful debugging information\n",
    "    print(\"\\nDebugging information:\")\n",
    "    print(f\"  Working directory: {os.getcwd()}\")\n",
    "    print(f\"  Python path: {sys.path[:3]}...\")  # Show first 3 entries\n",
    "    print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB allocated\")\n",
    "        \n",
    "finally:\n",
    "    # Cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nGPU Memory after training:\")\n",
    "        print(f\"  Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "        print(f\"  Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained policy\n",
    "print(\"=\"*50)\n",
    "print(\"Testing the trained policy...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Find the latest checkpoint\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Look for checkpoints in the runs directory\n",
    "checkpoint_patterns = [\"runs/*/final_ckpt.pt\", \"runs/*/best_ckpt.pt\", \"runs/*/*.pt\"]\n",
    "checkpoint_files = []\n",
    "for pattern in checkpoint_patterns:\n",
    "    checkpoint_files.extend(glob.glob(pattern))\n",
    "\n",
    "if checkpoint_files:\n",
    "    # Sort by modification time to get the latest\n",
    "    latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
    "    print(f\"‚úì Found checkpoint: {latest_checkpoint}\")\n",
    "    \n",
    "    # Show available checkpoints\n",
    "    print(\"\\nAvailable checkpoints:\")\n",
    "    for i, ckpt in enumerate(sorted(checkpoint_files, key=os.path.getctime, reverse=True)[:5]):\n",
    "        size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "        mtime = os.path.getmtime(ckpt)\n",
    "        print(f\"  {i+1}. {ckpt} ({size_mb:.1f} MB, {time.ctime(mtime)})\")\n",
    "\n",
    "    # Manual testing with visualization\n",
    "    print(f\"\\nüìä Manual testing with {latest_checkpoint}...\")\n",
    "    \n",
    "    try:\n",
    "        from ppo_rgb import Agent\n",
    "        import torch\n",
    "        import time\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        # Create environment (no GUI rendering in Colab)\n",
    "        env = PiperEnv(render_mode=None)\n",
    "        sample_obs, _ = env.reset()\n",
    "\n",
    "        # Load the trained agent\n",
    "        agent = Agent(env, sample_obs)\n",
    "        agent.load_state_dict(torch.load(latest_checkpoint, map_location=device))\n",
    "        agent.eval()\n",
    "        print(\"‚úì Agent loaded successfully\")\n",
    "\n",
    "        # Test for multiple episodes with statistics\n",
    "        num_test_episodes = 5\n",
    "        episode_rewards = []\n",
    "        episode_lengths = []\n",
    "        success_count = 0\n",
    "        \n",
    "        print(f\"\\nRunning {num_test_episodes} test episodes...\")\n",
    "        \n",
    "        for episode in range(num_test_episodes):\n",
    "            obs, _ = env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            step_count = 0\n",
    "            \n",
    "            # Store observations for visualization\n",
    "            rgb_frames = []\n",
    "            wrist_frames = []\n",
    "            \n",
    "            while not done and step_count < 200:  # Limit steps per episode\n",
    "                # Store frames (every 10 steps to save memory)\n",
    "                if step_count % 10 == 0:\n",
    "                    rgb_frames.append(obs['rgb'])\n",
    "                    wrist_frames.append(obs['wrist_cam'])\n",
    "                \n",
    "                # Get action from trained agent\n",
    "                with torch.no_grad():\n",
    "                    action = agent.get_action(obs, deterministic=True)\n",
    "                    action = action.cpu().numpy()\n",
    "\n",
    "                obs, reward, terminated, truncated, info = env.step(action)\n",
    "                episode_reward += reward\n",
    "                step_count += 1\n",
    "                done = terminated or truncated\n",
    "                \n",
    "                # Check for success\n",
    "                if info.get('is_success', False):\n",
    "                    success_count += 1\n",
    "\n",
    "            episode_rewards.append(episode_reward)\n",
    "            episode_lengths.append(step_count)\n",
    "            \n",
    "            print(f\"  Episode {episode + 1}: Reward = {episode_reward:.3f}, Steps = {step_count}, Success = {info.get('is_success', False)}\")\n",
    "            \n",
    "            # Show final frames from last episode\n",
    "            if episode == num_test_episodes - 1 and rgb_frames:\n",
    "                fig, axes = plt.subplots(2, min(4, len(rgb_frames)), figsize=(12, 6))\n",
    "                if len(rgb_frames) == 1:\n",
    "                    axes = axes.reshape(2, 1)\n",
    "                \n",
    "                for i, idx in enumerate(np.linspace(0, len(rgb_frames)-1, min(4, len(rgb_frames)), dtype=int)):\n",
    "                    axes[0, i].imshow(rgb_frames[idx])\n",
    "                    axes[0, i].set_title(f'3rd Person (Step {idx*10})')\n",
    "                    axes[0, i].axis('off')\n",
    "                    \n",
    "                    axes[1, i].imshow(wrist_frames[idx])\n",
    "                    axes[1, i].set_title(f'Wrist Camera (Step {idx*10})')\n",
    "                    axes[1, i].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "        env.close()\n",
    "        \n",
    "        # Display statistics\n",
    "        print(f\"\\nüìà Test Results Summary:\")\n",
    "        print(f\"  Average Reward: {np.mean(episode_rewards):.3f} ¬± {np.std(episode_rewards):.3f}\")\n",
    "        print(f\"  Average Episode Length: {np.mean(episode_lengths):.1f} ¬± {np.std(episode_lengths):.1f}\")\n",
    "        print(f\"  Success Rate: {success_count}/{num_test_episodes} ({100*success_count/num_test_episodes:.1f}%)\")\n",
    "        print(f\"  Min/Max Reward: {np.min(episode_rewards):.3f} / {np.max(episode_rewards):.3f}\")\n",
    "        \n",
    "        # Plot results\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        ax1.plot(episode_rewards, 'o-')\n",
    "        ax1.set_title('Episode Rewards')\n",
    "        ax1.set_xlabel('Episode')\n",
    "        ax1.set_ylabel('Reward')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        ax2.plot(episode_lengths, 'o-', color='orange')\n",
    "        ax2.set_title('Episode Lengths')\n",
    "        ax2.set_xlabel('Episode')\n",
    "        ax2.set_ylabel('Steps')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úì Manual testing completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Manual testing failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint files found.\")\n",
    "    print(\"Please check that training completed successfully and checkpoint files exist in the runs/ directory.\")\n",
    "    print(\"\\nLooking for files in runs/ directory:\")\n",
    "    if os.path.exists(\"runs\"):\n",
    "        for root, dirs, files in os.walk(\"runs\"):\n",
    "            for file in files:\n",
    "                print(f\"  {os.path.join(root, file)}\")\n",
    "    else:\n",
    "        print(\"  runs/ directory does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleanup and model saving\n",
    "print(\"=\"*50)\n",
    "print(\"Training Session Cleanup and Model Management\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Check the saved models and create a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"Session timestamp: {timestamp}\")\n",
    "\n",
    "if os.path.exists(\"runs/\"):\n",
    "    print(\"\\nüìÅ Checking saved models in runs/ directory:\")\n",
    "    \n",
    "    total_size = 0\n",
    "    checkpoint_count = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(\"runs/\"):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            size = os.path.getsize(filepath)\n",
    "            total_size += size\n",
    "            \n",
    "            if file.endswith('.pt'):\n",
    "                checkpoint_count += 1\n",
    "                print(f\"  ‚úì {filepath} ({size / (1024*1024):.1f} MB)\")\n",
    "            elif file.endswith('.txt') or file.endswith('.log'):\n",
    "                print(f\"  üìÑ {filepath} ({size / 1024:.1f} KB)\")\n",
    "    \n",
    "    print(f\"\\nSummary: {checkpoint_count} checkpoints, total size: {total_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    # 2. Copy models to Google Drive with timestamp\n",
    "    drive_path = f\"/content/drive/MyDrive/ppo_training_runs/session_{timestamp}\"\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(\"/content/drive/MyDrive/ppo_training_runs/\"):\n",
    "            os.makedirs(\"/content/drive/MyDrive/ppo_training_runs/\")\n",
    "        \n",
    "        print(f\"\\nüíæ Copying models to Google Drive: {drive_path}\")\n",
    "        shutil.copytree(\"runs/\", drive_path)\n",
    "        \n",
    "        # Create a summary file\n",
    "        summary_path = f\"{drive_path}/session_summary.txt\"\n",
    "        with open(summary_path, 'w') as f:\n",
    "            f.write(f\"PPO Training Session Summary\\n\")\n",
    "            f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "            f.write(f\"Total timesteps: {ppo_args.total_timesteps:,}\\n\")\n",
    "            f.write(f\"Number of environments: {ppo_args.num_envs}\\n\")\n",
    "            f.write(f\"Learning rate: {ppo_args.learning_rate}\\n\")\n",
    "            f.write(f\"Checkpoints: {checkpoint_count}\\n\")\n",
    "            f.write(f\"Total size: {total_size / (1024*1024):.1f} MB\\n\")\n",
    "            f.write(f\"CUDA used: {ppo_args.cuda}\\n\")\n",
    "        \n",
    "        print(f\"‚úì Models successfully copied to Google Drive\")\n",
    "        print(f\"‚úì Session summary saved to: {summary_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to copy to Google Drive: {e}\")\n",
    "        print(\"You may need to mount Google Drive first or check permissions.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No runs/ directory found. Training may not have completed successfully.\")\n",
    "\n",
    "# 3. Show training artifacts\n",
    "print(f\"\\nüìä Training Artifacts Generated:\")\n",
    "artifacts = []\n",
    "if os.path.exists(\"runs/\"):\n",
    "    for root, dirs, files in os.walk(\"runs/\"):\n",
    "        for file in files:\n",
    "            artifacts.append(os.path.join(root, file))\n",
    "\n",
    "for artifact in sorted(artifacts)[:10]:  # Show first 10\n",
    "    print(f\"  üìÑ {artifact}\")\n",
    "if len(artifacts) > 10:\n",
    "    print(f\"  ... and {len(artifacts) - 10} more files\")\n",
    "\n",
    "# 4. Memory cleanup\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"\\nüßπ GPU memory cleared\")\n",
    "    print(f\"  Current GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# 5. Next steps and recommendations\n",
    "print(f\"\\nüéØ Next Steps and Recommendations:\")\n",
    "print(f\"\")\n",
    "print(f\"1. üì• Download your models:\")\n",
    "print(f\"   - Check Google Drive: /MyDrive/ppo_training_runs/session_{timestamp}/\")\n",
    "print(f\"   - Download the entire folder for local testing\")\n",
    "print(f\"\")\n",
    "print(f\"2. üîß Improve training (if needed):\")\n",
    "print(f\"   - Increase total_timesteps to 1M+ for better performance\")\n",
    "print(f\"   - Adjust learning_rate (try 1e-4 or 5e-4)\")\n",
    "print(f\"   - Increase num_envs if you have more GPU memory\")\n",
    "print(f\"\")\n",
    "print(f\"3. üìä Monitor training:\")\n",
    "print(f\"   - Enable wandb tracking for better visualization\")\n",
    "print(f\"   - Add tensorboard logging\")\n",
    "print(f\"   - Save training curves\")\n",
    "print(f\"\")\n",
    "print(f\"4. üöÄ Deploy your model:\")\n",
    "print(f\"   - Test on real robot hardware\")\n",
    "print(f\"   - Fine-tune with real-world data\")\n",
    "print(f\"   - Implement safety mechanisms\")\n",
    "print(f\"\")\n",
    "print(f\"5. üîÑ Colab session management:\")\n",
    "print(f\"   - This session will timeout after 12 hours\")\n",
    "print(f\"   - Consider using Colab Pro for longer sessions\")\n",
    "print(f\"   - Save intermediate checkpoints more frequently\")\n",
    "\n",
    "print(f\"\\nüéâ Training session completed successfully!\")\n",
    "print(f\"All models and logs have been saved to Google Drive.\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
